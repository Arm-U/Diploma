# Batch Card Generation Pipeline

This pipeline is designed to generate and evaluate vocabulary cards for language learning. It leverages Large Language Models (LLMs) through Azure OpenAI, with GPT-4o.1 as the default model, to create high-quality translations and example sentences for vocabulary learning.

## Table of Contents
- [Overview](#overview)
- [Pipeline Architecture](#pipeline-architecture)
- [Installation and Setup](#installation-and-setup)
- [Data Structures](#data-structures)
- [Core Functions](#core-functions)
- [Detailed Examples](#detailed-examples)
- [Error Handling and Logging](#error-handling-and-logging)
- [Advanced Features](#advanced-features)
- [Performance Considerations](#performance-considerations)
- [Troubleshooting](#troubleshooting)

## Overview

The batch card generation pipeline facilitates the creation of vocabulary cards for language learning by:

1. Taking vocabulary words with example sentences in a source language
2. Using a secondary language to provide additional context
3. Generating translations into a target language
4. Evaluating the quality of the translations
5. Improving translations that don't meet quality standards

The system handles batches of cards efficiently, with built-in error handling, retry mechanisms, and detailed logging to ensure robust operation.

## Pipeline Architecture

The pipeline follows this workflow:

1. **Card Preparation**
   - Source and secondary language cards are extracted from a base dataset
   - Cards are organized into batches for efficient processing

2. **Initial Generation**
   - Each batch is sent to the LLM for translation
   - The model generates target language words and sentences

3. **Evaluation**
   - Generated cards are evaluated for:
     - Sentence correctness
     - Word usage
     - Word translation accuracy
     - Sentence translation accuracy

4. **Improvement Cycle**
   - Cards that fail evaluation are sent for improvement
   - The system uses evaluation feedback to guide improvements
   - Optionally uses Mixture of Agents (MoA) for challenging cases
   - Multiple improvement attempts are made if needed

5. **Result Collection**
   - Successful and failed cards are collected with their evaluations
   - Statistics are generated for the entire process

## Installation and Setup

### Requirements

- Python 3.8+
- Azure OpenAI API access
- Required Python packages:
  ```
  openai>=1.3.0
  python-dotenv
  tqdm
  ```

### Environment Configuration

Create a `.env` file in the project directory with the following variables:

```
OPENAI_API_KEY=your_openai_api_key
AZURE_OPENAI_API_KEY=your_azure_openai_api_key
AZURE_OPENAI_ENDPOINT_4o-1=https://your-resource-name.openai.azure.com/
```

### Setting Up Logging

The pipeline automatically creates a `logs` directory and logs detailed information to `batch_card_generation.log`. No additional setup is required, but ensure the application has write permissions to the directory where it's running.

## Data Structures

### Base Card Format

The input to `create_cards_list` is a list of cards with the following structure:

```json
[
  {
    "id": "card001",
    "translations": {
      "english": {
        "word": "apple",
        "sentence": "I eat an apple every day."
      },
      "finnish": {
        "word": "omena",
        "sentence": "Syön omenan joka päivä."
      }
    }
  },
  {
    "id": "card002",
    "translations": {
      "english": {
        "word": "book",
        "sentence": "I'm reading an interesting book."
      },
      "finnish": {
        "word": "kirja",
        "sentence": "Luen mielenkiintoista kirjaa."
      }
    }
  }
]
```

### Card Structure

After processing by `create_cards_list`, cards have this structure:

```json
{
  "word": "apple",
  "sentence": "I eat an apple every day.",
  "id": "card001"
}
```

### Generated Card Structure

Cards generated by the pipeline maintain the same structure:

```json
{
  "word": "яблоко",
  "sentence": "Я ем яблоко каждый день.",
  "id": "card001"
}
```

### Evaluation Result Structure

Evaluation results have detailed feedback for each criterion:

```json
{
  "sentenceCorrectness": {
    "isCorrect": true,
    "feedback": "The sentence is grammatically correct and natural-sounding in Russian."
  },
  "wordUsage": {
    "isCorrect": true, 
    "feedback": "The word 'яблоко' is used correctly in the sentence."
  },
  "wordTranslationAccuracy": {
    "isCorrect": true,
    "feedback": "The word 'яблоко' is an accurate translation of 'apple'."
  },
  "sentenceTranslationAccuracy": {
    "isCorrect": true,
    "feedback": "The sentence 'Я ем яблоко каждый день.' accurately conveys the meaning of 'I eat an apple every day.'"
  },
  "id": "card001"
}
```

### Failed Card Example

A failed card might look like this:

```json
// Failed Card
{
  "word": "книжка",
  "sentence": "Я читаю интересную книжка.",
  "id": "card002"
}

// Failed Evaluation
{
  "sentenceCorrectness": {
    "isCorrect": false,
    "feedback": "The sentence has a grammatical error. The word 'книжка' (feminine noun) should be in accusative case as 'книжку' since it's the direct object of the verb 'читаю'."
  },
  "wordUsage": {
    "isCorrect": false, 
    "feedback": "The word 'книжка' is used with incorrect case agreement."
  },
  "wordTranslationAccuracy": {
    "isCorrect": true,
    "feedback": "The word 'книжка' is an acceptable translation of 'book', though 'книга' is more common for a regular book."
  },
  "sentenceTranslationAccuracy": {
    "isCorrect": true,
    "feedback": "The sentence conveys the meaning of the original, despite the grammatical error."
  },
  "id": "card002"
}
```

## Core Functions

### `create_cards_list(base_cards, source_key, secondary_key)`

Prepares the source and secondary language cards from a base dataset.

**Parameters:**
- `base_cards`: List of cards with translations in multiple languages
- `source_key`: Key for the source language (e.g., "english")
- `secondary_key`: Key for the secondary language (e.g., "finnish")

**Returns:**
- A tuple of `(source_cards, secondary_cards)`

### `generate_batch_unified_cards(source_cards, secondary_cards, source_lang, target_lang, secondary_lang, model, system_prompt)`

Generates translations for a batch of cards.

**Parameters:**
- `source_cards`: List of cards in the source language
- `secondary_cards`: List of cards in the secondary language
- `source_lang`: Name of the source language (e.g., "English")
- `target_lang`: Name of the target language (e.g., "Russian")
- `secondary_lang`: Name of the secondary language (e.g., "Finnish")
- `model`: GPT model to use (default: "gpt-4o.1")
- `system_prompt`: Optional custom system prompt

**Returns:**
- List of generated cards in the target language

### `evaluate_batch_unified_cards(source_cards, secondary_cards, target_cards, source_lang, target_lang, secondary_lang, model)`

Evaluates the quality of generated translations.

**Parameters:**
- `source_cards`: List of cards in the source language
- `secondary_cards`: List of cards in the secondary language
- `target_cards`: List of generated cards in the target language
- `source_lang`: Name of the source language
- `target_lang`: Name of the target language
- `secondary_lang`: Name of the secondary language
- `model`: GPT model to use (default: "gpt-4o.1")

**Returns:**
- List of evaluation results

### `process_cards_batch(source_cards, secondary_cards, source_lang, target_lang, secondary_lang, model, batch_size, max_improvement_attempts, max_retries, retry_delay, use_moa)`

The main function that orchestrates the entire pipeline.

**Parameters:**
- `source_cards`: List of cards in the source language
- `secondary_cards`: List of cards in the secondary language
- `source_lang`: Name of the source language
- `target_lang`: Name of the target language
- `secondary_lang`: Name of the secondary language
- `model`: GPT model to use (default: "gpt-4o.1")
- `batch_size`: Number of cards to process in each batch (default: 3)
- `max_improvement_attempts`: Maximum number of attempts to improve a card (default: 3)
- `max_retries`: Maximum number of retries for API failures (default: 5)
- `retry_delay`: Delay in seconds between retries (default: 5)
- `use_moa`: Whether to use Mixture of Agents for improvement (default: False)

**Returns:**
- `successful_cards`: List of cards that passed evaluation
- `successful_evals`: Evaluation results for successful cards
- `failed_cards`: List of cards that did not pass evaluation
- `failed_evals`: Evaluation results for failed cards

## Detailed Examples

### Complete Workflow Example

Here's a complete example of using the pipeline:

```python
from batch_card_generation_pipeline import create_cards_list, process_cards_batch
import json

# Load base cards from a JSON file
with open('vocabulary_data.json', 'r', encoding='utf-8') as f:
    base_cards = json.load(f)

# Prepare the cards
source_cards, secondary_cards = create_cards_list(
    base_cards, 
    source_key="english", 
    secondary_key="finnish"
)

# Process the cards
successful_cards, successful_evals, failed_cards, failed_evals = process_cards_batch(
    source_cards,
    secondary_cards,
    source_lang="English",
    target_lang="Russian", 
    secondary_lang="Finnish",
    model="gpt-4o.1",
    batch_size=5,
    max_improvement_attempts=2,
    max_retries=3,
    retry_delay=5,
    use_moa=True
)

# Print statistics
print(f"Successfully processed: {len(successful_cards)} cards")
print(f"Failed to process: {len(failed_cards)} cards")

# Save the results
results = {
    "successful": [
        {"card": card, "evaluation": eval_result} 
        for card, eval_result in zip(successful_cards, successful_evals)
    ],
    "failed": [
        {"card": card, "evaluation": eval_result} 
        for card, eval_result in zip(failed_cards, failed_evals)
    ]
}

with open('processed_cards.json', 'w', encoding='utf-8') as f:
    json.dump(results, f, ensure_ascii=False, indent=2)
```

### Improving Failed Cards Example

If you want to specifically focus on improving failed cards:

```python
# Take failed cards from a previous run
failed_source_cards = [source_cards[i] for i, card in enumerate(failed_cards)]
failed_secondary_cards = [secondary_cards[i] for i, card in enumerate(failed_cards)]

# Try again with Mixture of Agents
improved_successful, improved_evals, still_failed, still_failed_evals = process_cards_batch(
    failed_source_cards,
    failed_secondary_cards,
    source_lang="English",
    target_lang="Russian", 
    secondary_lang="Finnish",
    model="gpt-4o.1",
    batch_size=3,
    max_improvement_attempts=5,  # More attempts
    use_moa=True  # Enable MoA
)

print(f"Successfully improved: {len(improved_successful)} cards")
print(f"Still failed: {len(still_failed)} cards")
```

## Error Handling and Logging

The pipeline includes comprehensive error handling:

1. **API Failures**: Automatic retries with exponential backoff
2. **Parsing Errors**: Robust JSON parsing with fallbacks
3. **Batch Processing**: Failed batches don't stop the entire process
4. **Detailed Logging**: Comprehensive logs for debugging

Logs are stored in `logs/batch_card_generation.log` with the following information:
- Timestamp
- Log level
- File and line number
- Detailed message

Example log entries:

```
2025-05-26 23:45:12 - INFO - [batch_card_generation_pipeline.py:740] - Starting card processing with 10 cards
2025-05-26 23:45:15 - INFO - [batch_card_generation_pipeline.py:758] - Processing initial batch of 3 cards
2025-05-26 23:45:30 - INFO - [batch_card_generation_pipeline.py:772] - Generated 3 cards
2025-05-26 23:45:45 - INFO - [batch_card_generation_pipeline.py:782] - Evaluated 3 cards. Success rate: 66.67%
2025-05-26 23:45:46 - INFO - [batch_card_generation_pipeline.py:835] - Attempting to improve 1 unsuccessful cards
2025-05-26 23:46:01 - ERROR - [batch_card_generation_pipeline.py:862] - Error improving batch (attempt 1/5): Rate limit exceeded
2025-05-26 23:46:07 - INFO - [batch_card_generation_pipeline.py:869] - Successfully improved 1 cards
```

## Advanced Features

### Mixture of Agents (MoA)

The MoA approach improves translation quality by:

1. **Multiple Translation Strategies**: Generates translations using different system prompts:
   - Direct translation focus
   - Natural language focus
   - Cultural sensitivity focus
   - Grammar and accuracy focus

2. **Translation Combination**: Uses a regressor model to evaluate and combine the best elements from each translation

3. **Optimization**: The regressor selects the optimal translation or creates a hybrid version

When to use MoA:
- For languages with complex grammar
- For idiomatic expressions
- When high accuracy is required
- For challenging word translations with multiple possible interpretations

Enable MoA by setting `use_moa=True` in `process_cards_batch()`.

### Custom System Prompts

You can provide custom system prompts to both the generation and improvement functions:

```python
custom_prompt = """You are a multilingual assistant specialized in {source_lang} to {target_lang} translation.
You excel at maintaining nuance and culturally appropriate translations.
Focus on natural-sounding sentences that a native speaker would use."""

generated_cards = generate_batch_unified_cards(
    source_cards,
    secondary_cards,
    source_lang="English",
    target_lang="Russian",
    secondary_lang="Finnish",
    model="gpt-4o.1",
    system_prompt=custom_prompt
)
```

## Performance Considerations

### Batch Size Optimization

The optimal batch size depends on:
- Model token limits
- Card complexity
- Required processing speed

Recommendations:
- For GPT-4o.1: 3-5 cards per batch
- For simpler models: 5-10 cards per batch
- For very complex languages: 1-3 cards per batch

### Cost Efficiency

To optimize cost:
1. Use smaller batch sizes for initial testing
2. Adjust `max_improvement_attempts` based on success rates
3. Only use MoA for cards that fail standard improvement
4. Consider using simpler models for initial generation

### Processing Speed

Average processing times:
- Card generation: ~5-10 seconds per batch
- Card evaluation: ~5-10 seconds per batch
- Card improvement: ~10-15 seconds per batch
- MoA processing: ~30-40 seconds per card

## Troubleshooting

### Common Issues

1. **API Rate Limits**
   - **Symptom**: Repeated errors about rate limits
   - **Solution**: Increase `retry_delay` and reduce `batch_size`

2. **Low Success Rate**
   - **Symptom**: Many cards fail evaluation
   - **Solution**: Enable MoA, increase `max_improvement_attempts`, or check source data quality

3. **JSON Parsing Errors**
   - **Symptom**: Errors about invalid JSON responses
   - **Solution**: Check logs for the full response, may indicate an issue with the prompt or model

4. **Memory Issues**
   - **Symptom**: Process crashes with memory errors
   - **Solution**: Reduce batch size or process data in smaller chunks

### Getting Help

If you encounter persistent issues:
1. Check the log file for detailed error messages
2. Review the Azure OpenAI service status
3. Ensure your API keys and endpoints are correctly configured in `.env`
